import streamlit as st
import pandas as pd
import sqlite3
import random
from datetime import datetime, timedelta
import time

# ---------------------------------------------------------
# [å®‰è£èˆ‡åŸ·è¡Œæ•™å­¸]
# 1. ç¢ºä¿å·²å®‰è£å¥—ä»¶: pip install streamlit pandas matplotlib
# 2. åœ¨çµ‚ç«¯æ©Ÿ(Terminal)åŸ·è¡Œ: streamlit run ecommerce_price_dashboard.py
# ---------------------------------------------------------

# --- è¨­å®šé é¢é…ç½® ---
st.set_page_config(page_title="é›»å•†ç«¶å“åƒ¹æ ¼è¿½è¹¤å„€è¡¨æ¿", layout="wide")

# --- è³‡æ–™åº«è¨­å®š (ä½¿ç”¨ SQLite æœ¬åœ°è³‡æ–™åº«) ---
DB_NAME = "ecommerce_prices.db"

def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«èˆ‡è³‡æ–™è¡¨"""
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    # å»ºç«‹è¡¨æ ¼ï¼šè¨˜éŒ„æ—¥æœŸ, å¹³å°, å•†å“åç¨±, åƒ¹æ ¼
    c.execute('''
        CREATE TABLE IF NOT EXISTS prices (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            date TEXT,
            platform TEXT,
            product_name TEXT,
            price INTEGER
        )
    ''')
    conn.commit()
    conn.close()

def generate_mock_data():
    """
    ç”Ÿæˆéå» 30 å¤©çš„æ¨¡æ“¬æ•¸æ“š (ç‚ºäº†è®“åœ–è¡¨ä¸€é–‹å§‹å°±æœ‰æ±è¥¿çœ‹)
    æ¨¡æ“¬æƒ…å¢ƒï¼šPChome å’Œ Momo å…©å¤§å¹³å°é‡å° iPhone 15 å’Œ Dyson å¹é¢¨æ©Ÿçš„åƒ¹æ ¼æˆ°
    """
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰è³‡æ–™ï¼Œè‹¥æœ‰å‰‡ä¸é‡æ–°ç”Ÿæˆ
    c.execute("SELECT count(*) FROM prices")
    if c.fetchone()[0] > 0:
        conn.close()
        return

    products = ["iPhone 15 128G", "Dyson Supersonic å¹é¢¨æ©Ÿ", "Sony WH-1000XM5 è€³æ©Ÿ"]
    platforms = ["PChome 24h", "Momo è³¼ç‰©ç¶²"]
    
    # åŸºæº–åƒ¹æ ¼
    base_prices = {
        "iPhone 15 128G": 29900,
        "Dyson Supersonic å¹é¢¨æ©Ÿ": 12900,
        "Sony WH-1000XM5 è€³æ©Ÿ": 9900
    }

    print("æ­£åœ¨ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š...")
    for day in range(30):
        current_date = (datetime.now() - timedelta(days=30-day)).strftime("%Y-%m-%d")
        
        for p_name in products:
            base = base_prices[p_name]
            for platform in platforms:
                # æ¨¡æ“¬åƒ¹æ ¼æ³¢å‹•ï¼šéš¨æ©Ÿå¢æ¸› 5%
                fluctuation = random.uniform(0.95, 1.05)
                # é€±æœ«å¯èƒ½æœƒç‰¹åƒ¹ (æ¨¡æ“¬è¡ŒéŠ·æ´»å‹•)
                if datetime.strptime(current_date, "%Y-%m-%d").weekday() >= 5: 
                    fluctuation -= 0.03 # é€±æœ«å†é™ 3%
                
                final_price = int(base * fluctuation)
                # å–æ•´æ•¸ (ä¾‹å¦‚ 29900 -> 29500) è®“åƒ¹æ ¼çœ‹èµ·ä¾†æ›´åƒçœŸçš„
                final_price = round(final_price / 100) * 100 
                
                c.execute("INSERT INTO prices (date, platform, product_name, price) VALUES (?, ?, ?, ?)",
                          (current_date, platform, p_name, final_price))
    
    conn.commit()
    conn.close()

def fetch_data(product_name):
    """å¾è³‡æ–™åº«è®€å–ç‰¹å®šå•†å“çš„æ­·å²åƒ¹æ ¼"""
    conn = sqlite3.connect(DB_NAME)
    query = f"SELECT date, platform, price FROM prices WHERE product_name = '{product_name}' ORDER BY date"
    df = pd.read_sql(query, conn)
    conn.close()
    return df

def run_scraper_simulation():
    """
    æ¨¡æ“¬çˆ¬èŸ²åŸ·è¡Œï¼š
    åœ¨çœŸå¯¦å°ˆæ¡ˆä¸­ï¼Œé€™è£¡æœƒä½¿ç”¨ requests/BeautifulSoup æˆ– Selenium å»æŠ“å–å¯¦éš›ç¶²é ã€‚
    """
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    today = datetime.now().strftime("%Y-%m-%d")
    
    products = ["iPhone 15 128G", "Dyson Supersonic å¹é¢¨æ©Ÿ", "Sony WH-1000XM5 è€³æ©Ÿ"]
    platforms = ["PChome 24h", "Momo è³¼ç‰©ç¶²"]
    base_prices = {"iPhone 15 128G": 29900, "Dyson Supersonic å¹é¢¨æ©Ÿ": 12900, "Sony WH-1000XM5 è€³æ©Ÿ": 9900}
    
    new_data = []
    for p_name in products:
        for platform in platforms:
            # æ¨¡æ“¬ä»Šæ—¥æ–°åƒ¹æ ¼
            price = int(base_prices[p_name] * random.uniform(0.92, 1.02)) # æ¨¡æ“¬çªç„¶å¤§ç‰¹åƒ¹
            price = round(price / 100) * 100
            
            c.execute("INSERT INTO prices (date, platform, product_name, price) VALUES (?, ?, ?, ?)",
                      (today, platform, p_name, price))
            new_data.append(f"æŠ“å–æˆåŠŸ: {platform} - {p_name} : ${price}")
            
    conn.commit()
    conn.close()
    return new_data

# --- ä¸»ç¨‹å¼é‚è¼¯ ---

# 1. åˆå§‹åŒ–
init_db()
generate_mock_data()

# 2. å´é‚Šæ¬„æ§åˆ¶é …
st.sidebar.title("ğŸ” ç«¶å“åƒ¹æ ¼ç›£æ§ç³»çµ±")
st.sidebar.markdown("æ¨¡æ“¬é›»å•†ç‡Ÿé‹äººå“¡çš„ç›£æ§è¦–è§’")

product_list = ["iPhone 15 128G", "Dyson Supersonic å¹é¢¨æ©Ÿ", "Sony WH-1000XM5 è€³æ©Ÿ"]
selected_product = st.sidebar.selectbox("è«‹é¸æ“‡è¦åˆ†æçš„å•†å“", product_list)

st.sidebar.markdown("---")
st.sidebar.subheader("âš™ï¸ ç³»çµ±æ“ä½œ")
if st.sidebar.button("ğŸš€ åŸ·è¡Œå³æ™‚çˆ¬èŸ² (æ¨¡æ“¬)"):
    with st.spinner('æ­£åœ¨é€£ç·šè‡³å„å¤§é›»å•†å¹³å°...'):
        time.sleep(1.5) # å‡è£åœ¨è·‘
        logs = run_scraper_simulation()
    st.sidebar.success("è³‡æ–™æ›´æ–°å®Œæˆï¼")
    for log in logs:
        st.sidebar.text(log)
    st.rerun() # é‡æ–°æ•´ç†é é¢ä»¥é¡¯ç¤ºæ–°æ•¸æ“š

# 3. ä¸»è¦å…§å®¹å€
st.title(f"ğŸ“Š {selected_product} åƒ¹æ ¼è¶¨å‹¢åˆ†æ")

# è®€å–è³‡æ–™
df = fetch_data(selected_product)

# è¨ˆç®— KPI
latest_date = df['date'].max()
latest_df = df[df['date'] == latest_date]
lowest_price = latest_df['price'].min()
avg_price = int(latest_df['price'].mean())

col1, col2, col3 = st.columns(3)
col1.metric("ä»Šæ—¥æœ€ä½åƒ¹", f"${lowest_price:,}", delta_color="inverse")
col2.metric("ä»Šæ—¥å¸‚å ´å‡åƒ¹", f"${avg_price:,}")
col3.metric("è³‡æ–™æ›´æ–°æ—¥æœŸ", latest_date)

# 4. ç¹ªè£½äº’å‹•åœ–è¡¨
st.subheader("å¹³å°åƒ¹æ ¼èµ°å‹¢æ¯”è¼ƒ (PChome vs Momo)")

# å°‡è³‡æ–™è½‰ç½®ç‚ºé©åˆç¹ªåœ–çš„æ ¼å¼ (Pivot)
# Index: Date, Columns: Platform, Values: Price
chart_data = df.pivot(index='date', columns='platform', values='price')

# ä½¿ç”¨ Streamlit å…§å»ºçš„æŠ˜ç·šåœ– (åŸºæ–¼ Altair/Vega-Lite)
st.line_chart(chart_data)

# 5. å•†æ¥­æ´å¯Ÿåˆ†æ (æ¨¡æ“¬è‡ªå‹•ç”¢ç”Ÿçš„å ±å‘Š)
st.subheader("ğŸ’¡ å•†æ¥­æ´å¯Ÿå ±å‘Š")
insight_text = ""
p_pchome = latest_df[latest_df['platform'] == 'PChome 24h']['price'].values[0]
p_momo = latest_df[latest_df['platform'] == 'Momo è³¼ç‰©ç¶²']['price'].values[0]

if p_pchome < p_momo:
    diff = p_momo - p_pchome
    insight_text += f"âš ï¸ **è­¦ç¤º**ï¼šç›®å‰ **PChome 24h** åƒ¹æ ¼æ¯” Momo ä¾¿å®œ **${diff}**ã€‚å»ºè­°è¡ŒéŠ·åœ˜éšŠæª¢æŸ¥æ˜¯å¦éœ€è¦è·Ÿé€²é™åƒ¹ï¼Œæˆ–å¼·èª¿è´ˆå“å„ªå‹¢ã€‚"
elif p_momo < p_pchome:
    diff = p_pchome - p_momo
    insight_text += f"âš ï¸ **è­¦ç¤º**ï¼šç›®å‰ **Momo è³¼ç‰©ç¶²** åƒ¹æ ¼æ¯” PChome ä¾¿å®œ **${diff}**ã€‚è«‹æ³¨æ„ç«¶çˆ­å°æ‰‹çš„ä¿ƒéŠ·æ´»å‹•ã€‚"
else:
    insight_text += "âœ… ç›®å‰å…©å¤§å¹³å°åƒ¹æ ¼æŒå¹³ï¼Œå¸‚å ´è¡Œæƒ…ç©©å®šã€‚"

st.info(insight_text)

# 6. è©³ç´°è³‡æ–™è¡¨æ ¼
with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“šè³‡æ–™è¡¨"):
    st.dataframe(df.sort_values(by='date', ascending=False), use_container_width=True)

# 7. é å°¾èªªæ˜
st.markdown("---")
st.caption("é–‹ç™¼è€…: [EddieTcLee] | æŠ€è¡“æ£§: Python, Streamlit, SQLite | ç”¨é€”: ä¸­å±±å¤§å­¸è³‡ç®¡ç¢©å°ˆç­å‚™å¯©ä½œå“é›†å±•ç¤º")